{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad9d076a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q torch transformers datasets scikit-learn pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59bf7b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class X3DBackbone(nn.Module):\n",
    "    \"\"\"X3D-S backbone for video feature extraction\"\"\"\n",
    "    def __init__(self):\n",
    "        super(X3DBackbone, self).__init__()\n",
    "        # Simplified X3D-S architecture\n",
    "        self.conv1 = nn.Conv3d(3, 24, kernel_size=(1, 3, 3), \n",
    "                               stride=(1, 2, 2), padding=(0, 1, 1))\n",
    "        self.conv2 = nn.Conv3d(24, 48, kernel_size=(3, 3, 3), \n",
    "                               stride=(1, 2, 2), padding=(1, 1, 1))\n",
    "        self.conv3 = nn.Conv3d(48, 96, kernel_size=(3, 3, 3), \n",
    "                               stride=(2, 2, 2), padding=(1, 1, 1))\n",
    "        self.conv4 = nn.Conv3d(96, 192, kernel_size=(3, 3, 3), \n",
    "                               stride=(2, 2, 2), padding=(1, 1, 1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Input: [B, 3, T, W, H]\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))  # Output: [B, 192, T/4, W/16, H/16]\n",
    "        return x\n",
    "\n",
    "class ConditionalGroupNorm(nn.Module):\n",
    "    \"\"\"Conditional Group Normalization with PSNR conditioning\"\"\"\n",
    "    def __init__(self, num_features, num_groups=4):\n",
    "        super(ConditionalGroupNorm, self).__init__()\n",
    "        self.num_groups = num_groups\n",
    "        self.group_norm = nn.GroupNorm(num_groups, num_features)\n",
    "        \n",
    "        # Conditioning network for PSNR target\n",
    "        self.condition_net = nn.Sequential(\n",
    "            nn.Linear(1, 64),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(128, 2 * num_features)  # For gamma and beta\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, psnr_target):\n",
    "        # x: [B, C, T, H, W], psnr_target: [B, 1]\n",
    "        normalized = self.group_norm(x)\n",
    "        \n",
    "        # Generate conditioning parameters\n",
    "        log_psnr = torch.log10(psnr_target)\n",
    "        condition_params = self.condition_net(log_psnr)\n",
    "        \n",
    "        gamma, beta = condition_params.chunk(2, dim=1)\n",
    "        gamma = gamma.view(-1, x.size(1), 1, 1, 1)\n",
    "        beta = beta.view(-1, x.size(1), 1, 1, 1)\n",
    "        \n",
    "        return gamma * normalized + beta\n",
    "\n",
    "class H264QualityController(nn.Module):\n",
    "    \"\"\"Complete RTQC system for H.264 quality control\"\"\"\n",
    "    def __init__(self, num_classes=52):  # QP range 0-51\n",
    "        super(H264QualityController, self).__init__()\n",
    "        \n",
    "        self.backbone = X3DBackbone()\n",
    "        \n",
    "        # Prediction head with CGN blocks\n",
    "        self.pred_conv1 = nn.Conv3d(192, 256, kernel_size=3, padding=1)\n",
    "        self.cgn1 = ConditionalGroupNorm(256)\n",
    "        \n",
    "        self.pred_conv2 = nn.Conv3d(256, 512, kernel_size=3, padding=1)\n",
    "        self.cgn2 = ConditionalGroupNorm(512)\n",
    "        \n",
    "        # Global average pooling and classifier\n",
    "        self.global_pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def forward(self, video_chunk, min_psnr):\n",
    "        # video_chunk: [B, 3, T, W, H], min_psnr: [B, 1]\n",
    "        features = self.backbone(video_chunk)\n",
    "        \n",
    "        # Apply prediction head with conditional normalization\n",
    "        x = F.relu(self.cgn1(self.pred_conv1(features), min_psnr))\n",
    "        x = F.relu(self.cgn2(self.pred_conv2(x), min_psnr))\n",
    "        \n",
    "        # Global pooling and classification\n",
    "        x = self.global_pool(x).flatten(1)\n",
    "        qp_logits = self.classifier(x)\n",
    "        \n",
    "        return qp_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8482c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def encode_h264_psnr(self, video_chunk, qp):\n",
    "        \"\"\"Real H.264 encoding and PSNR calculation using OpenCV\"\"\"\n",
    "        print(f\"encode_h264_psnr called with QP {qp.item()}\")\n",
    "        try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17530182",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qp_values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m qp \u001b[38;5;129;01min\u001b[39;00m \u001b[43mqp_values\u001b[49m:\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCalling encode_h264_psnr with QP \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mqp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m     psnr_value = pipeline.encode_h264_psnr(test_video, torch.tensor(qp))\n",
      "\u001b[31mNameError\u001b[39m: name 'qp_values' is not defined"
     ]
    }
   ],
   "source": [
    "    for qp in qp_values:\n",
    "        print(f\"Calling encode_h264_psnr with QP {qp}\")\n",
    "        psnr_value = pipeline.encode_h264_psnr(test_video, torch.tensor(qp))\n",
    "        print(f\"Returned PSNR = {psnr_value:.2f} dB (JPEG quality: {max(10, 100 - int(qp * 1.8))})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8181dadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import time\n",
    "\n",
    "class RealTimeH264Controller:\n",
    "    \"\"\"Integration with FFmpeg H.264 encoder for live streaming\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path, device='cuda'):\n",
    "        self.model = H264QualityController()\n",
    "        self.model.load_state_dict(torch.load(model_path))\n",
    "        self.model.to(device).eval()\n",
    "        self.device = device\n",
    "        \n",
    "    def encode_video_stream(self, input_stream, output_stream, target_psnr=35.0):\n",
    "        \"\"\"Process live video stream with adaptive QP control\"\"\"\n",
    "        \n",
    "        chunk_duration = 0.32  # seconds (8 frames at 25fps)\n",
    "        frame_buffer = []\n",
    "        \n",
    "        while True:\n",
    "            # Collect video chunk (8 consecutive frames)\n",
    "            chunk = self.collect_video_chunk(input_stream, chunk_duration)\n",
    "            if chunk is None:\n",
    "                break\n",
    "                \n",
    "            # Predict optimal QP\n",
    "            with torch.no_grad():\n",
    "                video_tensor = self.preprocess_chunk(chunk)\n",
    "                psnr_tensor = torch.tensor([[target_psnr]], device=self.device)\n",
    "                \n",
    "                qp_logits = self.model(video_tensor, psnr_tensor)\n",
    "                predicted_qp = torch.argmax(qp_logits, dim=1).item()\n",
    "                \n",
    "                # Apply conservative adjustment\n",
    "                adjusted_qp = max(0, predicted_qp - 1)\n",
    "            \n",
    "            # Encode chunk with predicted QP\n",
    "            encoded_chunk = self.encode_chunk_with_qp(chunk, adjusted_qp)\n",
    "            \n",
    "            # Stream encoded chunk\n",
    "            self.stream_chunk(encoded_chunk, output_stream)\n",
    "            \n",
    "            # Log performance metrics\n",
    "            actual_psnr = self.calculate_chunk_psnr(chunk, encoded_chunk)\n",
    "            bitrate = self.calculate_bitrate(encoded_chunk)\n",
    "            \n",
    "            print(f\"QP: {adjusted_qp}, PSNR: {actual_psnr:.2f}, \"\n",
    "                  f\"Bitrate: {bitrate:.0f} kbps\")\n",
    "    \n",
    "    def encode_chunk_with_qp(self, chunk, qp):\n",
    "        \"\"\"Encode video chunk using FFmpeg with specified QP\"\"\"\n",
    "        \n",
    "        # Prepare FFmpeg command with constant QP\n",
    "        cmd = [\n",
    "            'ffmpeg', '-y', '-f', 'rawvideo', '-pix_fmt', 'yuv420p',\n",
    "            '-s', '176x144', '-r', '25', '-i', '-',  # Input from stdin\n",
    "            '-c:v', 'libx264', '-qp', str(qp),\n",
    "            '-g', '8', '-keyint_min', '8',  # GOP size = 8\n",
    "            '-f', 'h264', '-'  # Output to stdout\n",
    "        ]\n",
    "        \n",
    "        # Execute encoding\n",
    "        process = subprocess.Popen(\n",
    "            cmd, stdin=subprocess.PIPE, stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.DEVNULL\n",
    "        )\n",
    "        \n",
    "        # Feed raw video data\n",
    "        raw_data = self.chunk_to_raw_bytes(chunk)\n",
    "        encoded_data, _ = process.communicate(input=raw_data)\n",
    "        \n",
    "        return encoded_data\n",
    "    \n",
    "    def preprocess_chunk(self, chunk):\n",
    "        \"\"\"Convert video chunk to tensor format\"\"\"\n",
    "        # chunk: numpy array [T, H, W, C] -> [1, C, T, H, W]\n",
    "        tensor = torch.from_numpy(chunk).float()\n",
    "        tensor = tensor.permute(3, 0, 1, 2).unsqueeze(0)  # Add batch dimension\n",
    "        tensor = tensor / 255.0  # Normalize to [0, 1]\n",
    "        return tensor.to(self.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be05037f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
